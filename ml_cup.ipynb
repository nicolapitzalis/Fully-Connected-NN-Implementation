{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network import NeuralNetwork\n",
    "from neural_network_utility import evaluate\n",
    "from math_functions.function_enums import LossFunction, ActivationFunction, Metrics\n",
    "from dataset_reader import read_monk, read_cup, read_old_cup\n",
    "from validation import kfold_cv, holdout, kfold_cv_ensemble\n",
    "from grid import grid_search, get_top_n_results, get_all_results\n",
    "from sklearn.utils import shuffle\n",
    "from utils import count_configs, save_top_plots, get_list_models, plot_over_epochs\n",
    "from ensemble import Ensemble\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save training data and internal test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data, targets = read_cup('datasets/cup/CUP_TR.csv')\n",
    "# train_data, test_data, train_targets, test_targets = holdout(data, targets, 0.8, shuffle_set=True)\n",
    "\n",
    "# np.savetxt(MODEL_SEL_DATA_PATH, train_data, delimiter=',')\n",
    "# np.savetxt(MODEL_SEL_TARGETS_PATH, train_targets, delimiter=',')\n",
    "# np.savetxt(MODEL_ASSESS_DATA_PATH, test_data, delimiter=',')\n",
    "# np.savetxt(MODEL_ASSESS_TARGETS_PATH, test_targets, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data and internal test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SEL_DATA_PATH = 'datasets/cup/grid_search/CUP_model_selection_data.csv'\n",
    "MODEL_SEL_TARGETS_PATH = 'datasets/cup/grid_search/CUP_model_selection_targets.csv'\n",
    "MODEL_ASSESS_DATA_PATH = 'datasets/cup/grid_search/CUP_model_assessment_data.csv'\n",
    "MODEL_ASSESS_TARGETS_PATH = 'datasets/cup/grid_search/CUP_model_assessment_targets.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.loadtxt(MODEL_SEL_DATA_PATH, delimiter=',')\n",
    "train_targets = np.loadtxt(MODEL_SEL_TARGETS_PATH, delimiter=',')\n",
    "test_data = np.loadtxt(MODEL_ASSESS_DATA_PATH, delimiter=',')\n",
    "test_targets = np.loadtxt(MODEL_ASSESS_TARGETS_PATH, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid over n_configurations: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:29<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 28\u001b[0m\n\u001b[1;32m      1\u001b[0m fixed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m      2\u001b[0m     n_output_units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, \n\u001b[1;32m      3\u001b[0m     training_loss_type_value\u001b[38;5;241m=\u001b[39mLossFunction\u001b[38;5;241m.\u001b[39mMSE\u001b[38;5;241m.\u001b[39mvalue, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     linear_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m grid_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m     25\u001b[0m     tao\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m500\u001b[39m]\n\u001b[1;32m     26\u001b[0m )\n\u001b[0;32m---> 28\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk_folds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mMetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMSE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMEE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_param\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrid_param\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrid_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_name_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     39\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/uni-ai/ML/ml-project/grid.py:42\u001b[0m, in \u001b[0;36mgrid_search\u001b[0;34m(k_folds, data, target, metrics, fixed_param, grid_param, file_name_results, verbose, plot, log_scale)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrid over n_configurations: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(all_combinations)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(all_combinations)) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m---> 42\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid_step\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk_folds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed_param\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_param\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_scale\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcombination\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mall_combinations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m     44\u001b[0m         pbar\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fixed_params = dict(\n",
    "    n_output_units=3, \n",
    "    training_loss_type_value=LossFunction.MSE.value, \n",
    "    validation_loss_type_value=LossFunction.MSE.value, \n",
    "    evaluation_metric_type_value=Metrics.MEE.value,\n",
    "    activation_hidden_type_value=ActivationFunction.SIGMOID.value, \n",
    "    activation_output_type_value=ActivationFunction.IDENTITY.value, \n",
    "    classification=False, \n",
    "    early_stopping=True, \n",
    "    fast_stopping=False,\n",
    "    patience=20, \n",
    "    tolerance=0.1,\n",
    "    epochs=500,\n",
    "    verbose=False,\n",
    "    hidden_layer_sizes=[64, 32],\n",
    "    learning_rate=0.0005,\n",
    "    mom_alpha=0,\n",
    "    reg_lambda=0,\n",
    "    batch_size=1,\n",
    "    nesterov=True,\n",
    "    linear_decay=True,\n",
    ")\n",
    "\n",
    "grid_params = dict(\n",
    "    tao=[200, 500]\n",
    ")\n",
    "\n",
    "results = grid_search(\n",
    "    k_folds=3, \n",
    "    data=train_data, \n",
    "    target=train_targets, \n",
    "    metrics=[Metrics.MSE.value, Metrics.MEE.value], \n",
    "    fixed_param=fixed_params, \n",
    "    grid_param=grid_params, \n",
    "    file_name_results=\"test\", \n",
    "    verbose=True,\n",
    "    plot=True,\n",
    "    log_scale=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_params = dict(\n",
    "    n_output_units=3, \n",
    "    training_loss_type_value=LossFunction.MSE.value, \n",
    "    validation_loss_type_value=LossFunction.MSE.value, \n",
    "    evaluation_metric_type_value=Metrics.MEE.value,\n",
    "    activation_hidden_type_value=ActivationFunction.SIGMOID.value, \n",
    "    activation_output_type_value=ActivationFunction.IDENTITY.value, \n",
    "    classification=False, \n",
    "    early_stopping=True, \n",
    "    fast_stopping=False,\n",
    "    patience=20, \n",
    "    tolerance=0.1,\n",
    "    epochs=500,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "grid_params = dict(\n",
    "    hidden_layer_sizes=[[64, 32], [128, 64], [128, 128], [64, 64, 32]],\n",
    "    learning_rate=[0.0005, 0.005, 0.05, 0.1],\n",
    "    mom_alpha=[0, 0.6, 0.7, 0.9],\n",
    "    reg_lambda=[0, 0.0001, 0.00001],\n",
    "    batch_size=[1, 64, 128],\n",
    "    nesterov=[True, False],\n",
    "    linear_decay=[True, False],\n",
    "    tao=[200, 500]\n",
    ")\n",
    "\n",
    "results = grid_search(\n",
    "    k_folds=3, \n",
    "    data=train_data, \n",
    "    target=train_targets, \n",
    "    metrics=[Metrics.MSE.value, Metrics.MEE.value], \n",
    "    fixed_param=fixed_params, \n",
    "    grid_param=grid_params, \n",
    "    file_name_results=\"test\", \n",
    "    verbose=True,\n",
    "    plot=True,\n",
    "    log_scale=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
