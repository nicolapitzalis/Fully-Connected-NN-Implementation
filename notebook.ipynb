{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_over_epochs(y_values: list, title: str, y_label: str, legend: str):\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.plot(list(range(len(y_values))), y_values, label=legend)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel(y_label)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network import NeuralNetwork\n",
    "from math_functions.loss import LossFunction\n",
    "from math_functions.activation import ActivationFunction\n",
    "from network_utility import Metrics\n",
    "from dataset_reader import read_monk, read_cup, read_old_cup\n",
    "from validation import kfold_cv, splitter\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. MONKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Monks-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_target = read_monk('datasets/monks/monks-1.train')\n",
    "test_data, test_target = read_monk('datasets/monks/monks-1.test')\n",
    "train_data, train_target = shuffle(train_data, train_target)\n",
    "\n",
    "train_data, val_data, train_target, val_target = splitter(train_data, train_target, 0.66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_monk1 = NeuralNetwork(\n",
    "    n_hidden_layers=1, \n",
    "    hidden_layer_sizes=[3], \n",
    "    n_output_units=1, \n",
    "    training_loss_type_value=LossFunction.MSE.value, \n",
    "    validation_loss_type_value=LossFunction.MSE.value, \n",
    "    evaluation_metric_type_value=Metrics.ACCURACY.value,\n",
    "    activation_hidden_type_value=ActivationFunction.SIGMOID.value, \n",
    "    activation_output_type_value=ActivationFunction.SIGMOID.value, \n",
    "    learning_rate=0.2,\n",
    "    reg_lambda=0,\n",
    "    mom_alpha=0.5,\n",
    "    epochs=500, \n",
    "    batch_size=1, \n",
    "    classification=True, \n",
    "    early_stopping=True, \n",
    "    linear_decay=True,\n",
    "    patience=30, \n",
    "    tollerance=0.00001,\n",
    "    tao=300, \n",
    "    verbose=False\n",
    "    ).train_net(train_data, train_target, val_data, val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_over_epochs(y_values=nn_monk1.training_losses, title='training loss over epochs', y_label='loss', legend='MSE training loss')\n",
    "plot_over_epochs(y_values=nn_monk1.training_evaluations, title='training accuracy over epochs', y_label='accuracy', legend='training accuracy')\n",
    "plot_over_epochs(y_values=nn_monk1.validation_losses, title='validation loss over epochs', y_label='loss', legend='MSE validation loss')\n",
    "plot_over_epochs(y_values=nn_monk1.validation_evaluations, title='validation accuracy over epochs', y_label='accuracy', legend='validation accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = nn_monk1.predict_and_evaluate(test_data, test_target, Metrics.ACCURACY.value)\n",
    "test_mse = nn_monk1.predict_and_evaluate(test_data, test_target, Metrics.MSE.value)\n",
    "test_mee = nn_monk1.predict_and_evaluate(test_data, test_target, Metrics.MEE.value)\n",
    "print(\"TEST RESULTS:\")\n",
    "print(f\"Accuracy: {test_accuracy} \\nMSE: {test_mse} \\nMEE: {test_mee}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Monks-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_target = read_monk('datasets/monks/monks-2.train')\n",
    "test_data, test_target = read_monk('datasets/monks/monks-2.test')\n",
    "train_data, train_target = shuffle(train_data, train_target)\n",
    "\n",
    "split_index = len(train_data) * 2 // 3\n",
    "train_data, val_data = train_data[:split_index], train_data[split_index:]\n",
    "train_target, val_target = train_target[:split_index], train_target[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_monk2 = NeuralNetwork(\n",
    "    n_hidden_layers=1,\n",
    "    hidden_layer_sizes=[3], \n",
    "    n_output_units=1, \n",
    "    training_loss_type_value=LossFunction.MSE.value, \n",
    "    validation_loss_type_value=LossFunction.MSE.value,\n",
    "    evaluation_metric_type_value=Metrics.ACCURACY.value,\n",
    "    activation_hidden_type_value=ActivationFunction.SIGMOID.value, \n",
    "    activation_output_type_value=ActivationFunction.SIGMOID.value, \n",
    "    learning_rate=0.2,\n",
    "    reg_lambda=0,\n",
    "    mom_alpha=0.9,\n",
    "    epochs=1000, \n",
    "    batch_size=1, \n",
    "    classification=True, \n",
    "    early_stopping=True, \n",
    "    linear_decay=True,\n",
    "    patience=20, \n",
    "    tollerance=0.00001,\n",
    "    tao=300, \n",
    "    verbose=False\n",
    "    ).train_net(train_data, train_target, test_data, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_over_epochs(y_values=nn_monk2.training_losses, title='MSE loss over epochs', y_label='loss', legend='MSE training loss')\n",
    "plot_over_epochs(y_values=nn_monk2.training_evaluations, title='training accuracy over epochs', y_label='accuracy', legend='training accuracy')\n",
    "plot_over_epochs(y_values=nn_monk2.validation_losses, title='MSE validation loss over epochs', y_label='loss', legend='MSE validation loss')\n",
    "plot_over_epochs(y_values=nn_monk2.validation_evaluations, title='validation accuracy over epochs', y_label='accuracy', legend='validation accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = nn_monk2.predict_and_evaluate(test_data, test_target, Metrics.ACCURACY.value)\n",
    "test_mse = nn_monk2.predict_and_evaluate(test_data, test_target, Metrics.MSE.value)\n",
    "test_mee = nn_monk2.predict_and_evaluate(test_data, test_target, Metrics.MEE.value)\n",
    "print(\"TEST RESULTS:\")\n",
    "print(f\"Accuracy: {test_accuracy} \\nMSE: {test_mse} \\nMEE: {test_mee}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Monks-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_target = read_monk('datasets/monks/monks-3.train')\n",
    "test_data, test_target = read_monk('datasets/monks/monks-3.test')\n",
    "train_data, train_target = shuffle(train_data, train_target)\n",
    "\n",
    "split_index = len(train_data) * 2 // 3\n",
    "train_data, val_data = train_data[:split_index], train_data[split_index:]\n",
    "train_target, val_target = train_target[:split_index], train_target[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_monk3 = NeuralNetwork(\n",
    "    n_hidden_layers=1, \n",
    "    hidden_layer_sizes=[3], \n",
    "    n_output_units=1, \n",
    "    training_loss_type_value=LossFunction.MSE.value, \n",
    "    validation_loss_type_value=LossFunction.MSE.value, \n",
    "    evaluation_metric_type_value=Metrics.ACCURACY.value,\n",
    "    activation_hidden_type_value=ActivationFunction.SIGMOID.value, \n",
    "    activation_output_type_value=ActivationFunction.SIGMOID.value, \n",
    "    learning_rate=0.02, \n",
    "    reg_lambda=0.0005,\n",
    "    mom_alpha=0.9,\n",
    "    epochs=1000, \n",
    "    batch_size=1, \n",
    "    classification=True, \n",
    "    early_stopping=True, \n",
    "    linear_decay=True,\n",
    "    patience=10, \n",
    "    tollerance=0.001, \n",
    "    tao=300,\n",
    "    verbose=False\n",
    "    ).train_net(train_data, train_target, test_data, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_over_epochs(y_values=nn_monk3.training_losses, title='MSE loss over epochs', y_label='loss', legend='MSE training loss')\n",
    "plot_over_epochs(y_values=nn_monk3.training_evaluations, title='training accuracy over epochs', y_label='accuracy', legend='training accuracy')\n",
    "plot_over_epochs(y_values=nn_monk3.validation_losses, title='MSE validation loss over epochs', y_label='loss', legend='MSE validation loss')\n",
    "plot_over_epochs(y_values=nn_monk3.validation_evaluations, title='validation accuracy over epochs', y_label='accuracy', legend='validation accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = nn_monk3.predict_and_evaluate(test_data, test_target, Metrics.ACCURACY.value)\n",
    "test_mse = nn_monk3.predict_and_evaluate(test_data, test_target, Metrics.MSE.value)\n",
    "test_mee = nn_monk3.predict_and_evaluate(test_data, test_target, Metrics.MEE.value)\n",
    "print(\"TEST RESULTS:\")\n",
    "print(f\"Accuracy: {test_accuracy} \\nMSE: {test_mse} \\nMEE: {test_mee}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Monks-3 Kfold-cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = read_monk('datasets/monks/monks-3.train')\n",
    "\n",
    "config = dict(\n",
    "    n_hidden_layers=1, \n",
    "    hidden_layer_sizes=[3], \n",
    "    n_output_units=1, \n",
    "    training_loss_type_value=LossFunction.MSE.value, \n",
    "    validation_loss_type_value=LossFunction.MSE.value, \n",
    "    activation_hidden_type_value=ActivationFunction.SIGMOID.value, \n",
    "    activation_output_type_value=ActivationFunction.SIGMOID.value, \n",
    "    learning_rate=0.02, \n",
    "    reg_lambda=0.0005,\n",
    "    mom_alpha=0.9,\n",
    "    epochs=1000, \n",
    "    batch_size=1, \n",
    "    classification=True, \n",
    "    early_stopping=True, \n",
    "    linear_decay=True,\n",
    "    patience=60, \n",
    "    tollerance=0.001, \n",
    "    tao=300,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "metrics = [Metrics.MSE.value, Metrics.MEE.value, Metrics.ACCURACY.value]\n",
    "kfold_cv(10, data, target, metrics, cv_verbose=True, **config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. OLD ML_CUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets = read_old_cup('datasets/cup/ML-CUP22-TR.csv')\n",
    "train_data, test_data, train_target, test_target = splitter(data, targets, 0.8)\n",
    "shuffle(train_data, train_target)\n",
    "shuffle(test_data, test_data)\n",
    "\n",
    "train_data, validation_data, train_target, validation_target = splitter(train_data, train_target, 0.66)\n",
    "shuffle(train_data, train_target)\n",
    "shuffle(validation_data, validation_target)\n",
    "\n",
    "nn = NeuralNetwork(\n",
    "    n_hidden_layers=2, \n",
    "    hidden_layer_sizes=[60, 30], \n",
    "    n_output_units=2, \n",
    "    training_loss_type_value=LossFunction.MSE.value, \n",
    "    validation_loss_type_value=LossFunction.MSE.value, \n",
    "    evaluation_metric_type_value=Metrics.MEE.value,\n",
    "    activation_hidden_type_value=ActivationFunction.SIGMOID.value, \n",
    "    activation_output_type_value=ActivationFunction.IDENTITY.value, \n",
    "    learning_rate=0.6, \n",
    "    reg_lambda=0.00001,\n",
    "    mom_alpha=0.9,\n",
    "    epochs=500, \n",
    "    batch_size=train_data.shape[0], \n",
    "    classification=False, \n",
    "    early_stopping=True, \n",
    "    fast_stopping=True,\n",
    "    linear_decay=True,\n",
    "    patience=30, \n",
    "    tollerance=0.0001,\n",
    "    tao=300, \n",
    "    verbose=False\n",
    ").train_net(train_data, train_target, validation_data, validation_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_over_epochs(y_values=nn.training_losses, title='MSE loss over epochs', y_label='mse', legend='MSE training loss')\n",
    "plot_over_epochs(y_values=nn.validation_losses, title='MSE validation loss over epochs', y_label='mse', legend='MSE validation loss')\n",
    "plot_over_epochs(y_values=nn.training_evaluations, title='training MEE eval over epochs', y_label='mee', legend='MEE training eval')\n",
    "plot_over_epochs(y_values=nn.validation_evaluations, title='validation MEE eval over epochs', y_label='mee', legend='MEE validation eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mee = nn.predict_and_evaluate(test_data, test_target, Metrics.MEE.value)\n",
    "training_mee = nn.training_evaluations[-1]\n",
    "print(f\"Training MEE: {training_mee} \\nTest MEE: {test_mee}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets = read_old_cup('datasets/cup/ML-CUP22-TR.csv')\n",
    "train_data, test_data, train_target, test_target = splitter(data, targets, 0.8)\n",
    "\n",
    "config = dict(\n",
    "    n_hidden_layers=2, \n",
    "    hidden_layer_sizes=[60, 30], \n",
    "    n_output_units=2, \n",
    "    training_loss_type_value=LossFunction.MSE.value, \n",
    "    validation_loss_type_value=LossFunction.MSE.value, \n",
    "    evaluation_metric_type_value=Metrics.MEE.value,\n",
    "    activation_hidden_type_value=ActivationFunction.SIGMOID.value, \n",
    "    activation_output_type_value=ActivationFunction.IDENTITY.value, \n",
    "    learning_rate=0.005, \n",
    "    reg_lambda=0.00025,\n",
    "    mom_alpha=0.6,\n",
    "    epochs=500, \n",
    "    batch_size=1, \n",
    "    classification=False, \n",
    "    early_stopping=True, \n",
    "    fast_stopping=True,\n",
    "    linear_decay=True,\n",
    "    patience=30, \n",
    "    tollerance=0.00001,\n",
    "    tao=300, \n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "metrics_results = kfold_cv(5, train_data, train_target, [Metrics.MSE.value, Metrics.MEE.value], cv_verbose=True, **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ML_CUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets = read_cup('datasets/cup/CUP_TR.csv')\n",
    "train_data, test_data, train_target, test_target = splitter(data, targets, 0.8)\n",
    "\n",
    "train_data, validation_data, train_target, validation_target = splitter(train_data, train_target, 0.66)\n",
    "shuffle(train_data, train_target)\n",
    "shuffle(validation_data, validation_target)\n",
    "\n",
    "nn = NeuralNetwork(\n",
    "    n_hidden_layers=2, \n",
    "    hidden_layer_sizes=[60, 30], \n",
    "    n_output_units=3, \n",
    "    training_loss_type_value=LossFunction.MSE.value, \n",
    "    validation_loss_type_value=LossFunction.MSE.value, \n",
    "    evaluation_metric_type_value=Metrics.MEE.value,\n",
    "    activation_hidden_type_value=ActivationFunction.SIGMOID.value, \n",
    "    activation_output_type_value=ActivationFunction.IDENTITY.value, \n",
    "    learning_rate=0.005, \n",
    "    reg_lambda=0.00025,\n",
    "    mom_alpha=0.6,\n",
    "    epochs=500, \n",
    "    batch_size=1, \n",
    "    classification=False, \n",
    "    early_stopping=True, \n",
    "    fast_stopping=True,\n",
    "    linear_decay=True,\n",
    "    patience=30, \n",
    "    tollerance=0.001,\n",
    "    tao=300, \n",
    "    verbose=False\n",
    ").train_net(train_data, train_target, test_data, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_over_epochs(y_values=nn.training_losses, title='MSE loss over epochs', y_label='loss', legend='MSE training loss')\n",
    "plot_over_epochs(y_values=nn.validation_losses, title='MSE validation loss over epochs', y_label='loss', legend='MSE validation loss')\n",
    "plot_over_epochs(y_values=nn.training_evaluations, title='training MEE eval over epochs', y_label='mee', legend='MEE training eval')\n",
    "plot_over_epochs(y_values=nn.validation_evaluations, title='validation MEE eval over epochs', y_label='mee', legend='MEE validation eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mee = nn.predict_and_evaluate(test_data, test_target, Metrics.MEE.value)\n",
    "training_mee = nn.training_evaluations[-1]\n",
    "print(f\"Training MEE: {training_mee} \\nTest MEE: {test_mee}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
