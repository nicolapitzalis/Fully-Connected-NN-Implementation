{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network import NeuralNetwork\n",
    "from math_functions.loss import LossFunction\n",
    "from math_functions.activation import ActivationFunction\n",
    "from monks import read_monk\n",
    "\n",
    "train_data, train_target = read_monk('datasets/monks/monks-1.train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((124, 17), (124, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 31.13930953475329\n",
      "Epoch: 10, loss: 29.691916145934858\n",
      "Epoch: 20, loss: 19.688993252505615\n",
      "Epoch: 30, loss: 15.967872029885855\n",
      "Epoch: 40, loss: 15.582842110697047\n",
      "Epoch: 50, loss: 13.999927388601453\n",
      "Epoch: 60, loss: 13.447258917293732\n",
      "Epoch: 70, loss: 12.048946857180544\n",
      "Epoch: 80, loss: 11.021366875847423\n",
      "Epoch: 90, loss: 11.018043548954788\n",
      "Epoch: 100, loss: 11.000487290851252\n",
      "Epoch: 110, loss: 11.00527747094104\n",
      "Epoch: 120, loss: 9.99999582685314\n",
      "Epoch: 130, loss: 10.028837148098292\n",
      "Epoch: 140, loss: 10.052577958537709\n",
      "Epoch: 150, loss: 10.000191754512592\n",
      "Epoch: 160, loss: 10.000001844377817\n",
      "Epoch: 170, loss: 10.00000106410571\n",
      "Epoch: 180, loss: 10.000012520216979\n",
      "Epoch: 190, loss: 10.000275016409269\n",
      "Epoch: 200, loss: 10.0062669128388\n",
      "Epoch: 210, loss: 10.000011996918248\n",
      "Epoch: 220, loss: 9.999999991186504\n",
      "Epoch: 230, loss: 9.999999991659328\n",
      "Epoch: 240, loss: 10.00042969097638\n",
      "Epoch: 250, loss: 10.000002491815106\n",
      "Epoch: 260, loss: 9.999999998636877\n",
      "Epoch: 270, loss: 10.000000851096315\n",
      "Epoch: 280, loss: 9.972811614385915\n",
      "Epoch: 290, loss: 9.000000135127769\n",
      "Epoch: 300, loss: 8.999999999959192\n",
      "Epoch: 310, loss: 8.999999999981366\n",
      "Epoch: 320, loss: 8.000526286020582\n",
      "Epoch: 330, loss: 7.9999999999967\n",
      "Epoch: 340, loss: 7.999999999998626\n",
      "Epoch: 350, loss: 7.999999999999428\n",
      "Epoch: 360, loss: 7.999999999999762\n",
      "Epoch: 370, loss: 8.005046314867425\n",
      "Epoch: 380, loss: 7.999999999999957\n",
      "Epoch: 390, loss: 7.9999999999999805\n",
      "Epoch: 400, loss: 7.999999999999991\n",
      "Epoch: 410, loss: 7.999999999999996\n",
      "Epoch: 420, loss: 7.999999999999999\n",
      "Epoch: 430, loss: 8.0\n",
      "Epoch: 440, loss: 8.0\n",
      "Epoch: 450, loss: 8.0\n",
      "Epoch: 460, loss: 8.0\n",
      "Epoch: 470, loss: 8.0\n",
      "Epoch: 480, loss: 8.0\n",
      "Epoch: 490, loss: 8.0\n",
      "Epoch: 500, loss: 8.000000000000002\n",
      "Epoch: 510, loss: 8.000000000000107\n",
      "Epoch: 520, loss: 8.000000000009901\n",
      "Epoch: 530, loss: 8.00000000117378\n",
      "Epoch: 540, loss: 8.000000173392257\n",
      "Epoch: 550, loss: 8.000029922081467\n",
      "Epoch: 560, loss: 8.00038880587489\n",
      "Epoch: 570, loss: 8.000002940899739\n",
      "Epoch: 580, loss: 8.00000000980762\n",
      "Epoch: 590, loss: 8.00000000002676\n",
      "Epoch: 600, loss: 8.000000000000062\n",
      "Epoch: 610, loss: 8.0\n",
      "Epoch: 620, loss: 8.0\n",
      "Epoch: 630, loss: 8.0\n",
      "Epoch: 640, loss: 8.0\n",
      "Epoch: 650, loss: 8.0\n",
      "Epoch: 660, loss: 8.0\n",
      "Epoch: 670, loss: 8.0\n",
      "Epoch: 680, loss: 8.0\n",
      "Epoch: 690, loss: 8.0\n",
      "Epoch: 700, loss: 8.0\n",
      "Epoch: 710, loss: 8.0\n",
      "Epoch: 720, loss: 8.0\n",
      "Epoch: 730, loss: 8.0\n",
      "Epoch: 740, loss: 8.0\n",
      "Epoch: 750, loss: 8.0\n",
      "Epoch: 760, loss: 8.0\n",
      "Epoch: 770, loss: 8.0\n",
      "Epoch: 780, loss: 8.0\n",
      "Epoch: 790, loss: 8.0\n",
      "Epoch: 800, loss: 8.0\n",
      "Epoch: 810, loss: 8.0\n",
      "Epoch: 820, loss: 8.0\n",
      "Epoch: 830, loss: 8.0\n",
      "Epoch: 840, loss: 8.0\n",
      "Epoch: 850, loss: 8.0\n",
      "Epoch: 860, loss: 8.0\n",
      "Epoch: 870, loss: 8.0\n",
      "Epoch: 880, loss: 8.0\n",
      "Epoch: 890, loss: 8.0\n",
      "Epoch: 900, loss: 8.0\n",
      "Epoch: 910, loss: 8.0\n",
      "Epoch: 920, loss: 8.0\n",
      "Epoch: 930, loss: 8.0\n",
      "Epoch: 940, loss: 8.0\n",
      "Epoch: 950, loss: 8.0\n",
      "Epoch: 960, loss: 8.0\n",
      "Epoch: 970, loss: 9.0\n",
      "Epoch: 980, loss: 9.0\n",
      "Epoch: 990, loss: 9.0\n",
      "Epoch: 1000, loss: 11.0\n",
      "Epoch: 1010, loss: 12.0\n",
      "Epoch: 1020, loss: 12.00000000000001\n",
      "Epoch: 1030, loss: 15.0\n",
      "Epoch: 1040, loss: 16.0\n",
      "Epoch: 1050, loss: 16.0\n",
      "Epoch: 1060, loss: 16.0\n",
      "Epoch: 1070, loss: 16.99218676663225\n",
      "Epoch: 1080, loss: 16.0\n",
      "Epoch: 1090, loss: 16.0\n",
      "Epoch: 1100, loss: 14.000289768756028\n",
      "Epoch: 1110, loss: 13.0\n",
      "Epoch: 1120, loss: 12.0\n",
      "Epoch: 1130, loss: 11.0\n",
      "Epoch: 1140, loss: 11.0\n",
      "Epoch: 1150, loss: 10.999999992784527\n",
      "Epoch: 1160, loss: 10.0\n",
      "Epoch: 1170, loss: 8.0\n",
      "Epoch: 1180, loss: 8.0\n",
      "Epoch: 1190, loss: 8.0\n",
      "Epoch: 1200, loss: 8.0\n",
      "Epoch: 1210, loss: 8.0\n",
      "Epoch: 1220, loss: 8.0\n",
      "Epoch: 1230, loss: 8.0\n",
      "Epoch: 1240, loss: 8.0\n",
      "Epoch: 1250, loss: 8.0\n",
      "Epoch: 1260, loss: 8.0\n",
      "Epoch: 1270, loss: 8.0\n",
      "Epoch: 1280, loss: 8.0\n",
      "Epoch: 1290, loss: 8.0\n",
      "Epoch: 1300, loss: 8.0\n",
      "Epoch: 1310, loss: 8.0\n",
      "Epoch: 1320, loss: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolapitzalis/Documents/uni-ai/ML/ml-project/math_functions/activation.py:149: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1330, loss: 8.0\n",
      "Epoch: 1340, loss: 8.0\n",
      "Epoch: 1350, loss: 8.0\n",
      "Epoch: 1360, loss: 8.0\n",
      "Epoch: 1370, loss: 8.0\n",
      "Epoch: 1380, loss: 8.0\n",
      "Epoch: 1390, loss: 8.0\n",
      "Epoch: 1400, loss: 8.0\n",
      "Epoch: 1410, loss: 8.0\n",
      "Epoch: 1420, loss: 8.0\n",
      "Epoch: 1430, loss: 8.0\n",
      "Epoch: 1440, loss: 8.0\n",
      "Epoch: 1450, loss: 8.0\n",
      "Epoch: 1460, loss: 8.0\n",
      "Epoch: 1470, loss: 8.0\n",
      "Epoch: 1480, loss: 8.0\n",
      "Epoch: 1490, loss: 8.0\n",
      "Epoch: 1500, loss: 8.0\n",
      "Epoch: 1510, loss: 8.0\n",
      "Epoch: 1520, loss: 9.0\n",
      "Epoch: 1530, loss: 9.0\n",
      "Epoch: 1540, loss: 9.0\n",
      "Epoch: 1550, loss: 9.0\n",
      "Epoch: 1560, loss: 10.0\n",
      "Epoch: 1570, loss: 10.0\n",
      "Epoch: 1580, loss: 10.0\n",
      "Epoch: 1590, loss: 10.0\n",
      "Epoch: 1600, loss: 10.0\n",
      "Epoch: 1610, loss: 10.0\n",
      "Epoch: 1620, loss: 10.0\n",
      "Epoch: 1630, loss: 10.0\n",
      "Epoch: 1640, loss: 10.0\n",
      "Epoch: 1650, loss: 10.0\n",
      "Epoch: 1660, loss: 10.0\n",
      "Epoch: 1670, loss: 10.0\n",
      "Epoch: 1680, loss: 10.0\n",
      "Epoch: 1690, loss: 10.0\n",
      "Epoch: 1700, loss: 11.0\n",
      "Epoch: 1710, loss: 11.0\n",
      "Epoch: 1720, loss: 11.0\n",
      "Epoch: 1730, loss: 11.0\n",
      "Epoch: 1740, loss: 11.0\n",
      "Epoch: 1750, loss: 11.0\n",
      "Epoch: 1760, loss: 11.0\n",
      "Epoch: 1770, loss: 11.0\n",
      "Epoch: 1780, loss: 11.0\n",
      "Epoch: 1790, loss: 11.0\n",
      "Epoch: 1800, loss: 12.0\n",
      "Epoch: 1810, loss: 12.0\n",
      "Epoch: 1820, loss: 12.0\n",
      "Epoch: 1830, loss: 12.0\n",
      "Epoch: 1840, loss: 12.0\n",
      "Epoch: 1850, loss: 12.0\n",
      "Epoch: 1860, loss: 12.0\n",
      "Epoch: 1870, loss: 12.0\n",
      "Epoch: 1880, loss: 12.0\n",
      "Epoch: 1890, loss: 12.0\n",
      "Epoch: 1900, loss: 12.0\n",
      "Epoch: 1910, loss: 12.0\n",
      "Epoch: 1920, loss: 12.0\n",
      "Epoch: 1930, loss: 12.0\n",
      "Epoch: 1940, loss: 12.0\n",
      "Epoch: 1950, loss: 12.0\n",
      "Epoch: 1960, loss: 12.0\n",
      "Epoch: 1970, loss: 13.0\n",
      "Epoch: 1980, loss: 13.0\n",
      "Epoch: 1990, loss: 13.0\n",
      "Epoch: 2000, loss: 13.0\n",
      "Epoch: 2010, loss: 13.0\n",
      "Epoch: 2020, loss: 13.0\n",
      "Epoch: 2030, loss: 13.0\n",
      "Epoch: 2040, loss: 14.0\n",
      "Epoch: 2050, loss: 14.0\n",
      "Epoch: 2060, loss: 14.0\n",
      "Epoch: 2070, loss: 14.0\n",
      "Epoch: 2080, loss: 15.0\n",
      "Epoch: 2090, loss: 15.0\n",
      "Epoch: 2100, loss: 15.0\n",
      "Epoch: 2110, loss: 15.0\n",
      "Epoch: 2120, loss: 15.0\n",
      "Epoch: 2130, loss: 15.0\n",
      "Epoch: 2140, loss: 16.0\n",
      "Epoch: 2150, loss: 16.0\n",
      "Epoch: 2160, loss: 16.0\n",
      "Epoch: 2170, loss: 16.0\n",
      "Epoch: 2180, loss: 16.0\n",
      "Epoch: 2190, loss: 16.0\n",
      "Epoch: 2200, loss: 16.0\n",
      "Epoch: 2210, loss: 16.0\n",
      "Epoch: 2220, loss: 16.0\n",
      "Epoch: 2230, loss: 16.0\n",
      "Epoch: 2240, loss: 16.0\n",
      "Epoch: 2250, loss: 16.0\n",
      "Epoch: 2260, loss: 16.0\n",
      "Epoch: 2270, loss: 16.0\n",
      "Epoch: 2280, loss: 16.0\n",
      "Epoch: 2290, loss: 16.0\n",
      "Epoch: 2300, loss: 16.0\n",
      "Epoch: 2310, loss: 16.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/nicolapitzalis/Documents/uni-ai/ML/ml-project/notebook.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nicolapitzalis/Documents/uni-ai/ML/ml-project/notebook.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m nn \u001b[39m=\u001b[39m NeuralNetwork(\u001b[39m1\u001b[39;49m, [\u001b[39m3\u001b[39;49m], \u001b[39m1\u001b[39;49m, LossFunction\u001b[39m.\u001b[39;49mMSE\u001b[39m.\u001b[39;49mvalue, ActivationFunction\u001b[39m.\u001b[39;49mSIGMOID\u001b[39m.\u001b[39;49mvalue, ActivationFunction\u001b[39m.\u001b[39;49mSIGMOID\u001b[39m.\u001b[39;49mvalue, \u001b[39m0.0001\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(train_data, train_target, \u001b[39m100000\u001b[39;49m, train_data\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m])\n",
      "File \u001b[0;32m~/Documents/uni-ai/ML/ml-project/neural_network.py:70\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(self, X, Y, epochs, batch_size)\u001b[0m\n\u001b[1;32m     67\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(y_true\u001b[39m=\u001b[39my, y_pred\u001b[39m=\u001b[39moutput)\n\u001b[1;32m     68\u001b[0m loss_prime \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_prime(y_true\u001b[39m=\u001b[39my, y_pred\u001b[39m=\u001b[39moutput)\n\u001b[0;32m---> 70\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers))):\n\u001b[1;32m     71\u001b[0m     loss_prime \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[i]\u001b[39m.\u001b[39mbackward(loss_prime)\n\u001b[1;32m     72\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[i]\u001b[39m.\u001b[39mupdate_weight(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlearning_rate)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(1, [3], 1, LossFunction.MSE.value, ActivationFunction.SIGMOID.value, ActivationFunction.SIGMOID.value, 0.0001).fit(train_data, train_target, 100000, train_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "a = np.array([[1,2,3],[1,2,3]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [1, 2, 3]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 6])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(a, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
